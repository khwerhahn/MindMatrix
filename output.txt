
### services/OpenAIService.ts ###
Filename: OpenAIService.ts

import OpenAI from 'openai'; import { EmbeddingResponse } from '../models/DocumentChunk'; import { Notice } from 'obsidian'; import { ErrorHandler } from '../utils/ErrorHandler'; import { OpenAISettings } from '../settings/Settings';  export class OpenAIService { 	private client: OpenAI | null; 	private rateLimitDelay: number = 20; // ms between requests 	private lastRequestTime: number = 0; 	private readonly errorHandler: ErrorHandler; 	private settings: OpenAISettings;  	constructor(settings: OpenAISettings, errorHandler: ErrorHandler) { 		this.settings = settings; 		this.errorHandler = errorHandler;  		if (!settings.apiKey) { 			console.warn('OpenAI API key is missing. OpenAIService will not be initialized.'); 			this.client = null; 			return; 		}  		// Initialize OpenAI client with browser support 		this.client = new OpenAI({ 			apiKey: settings.apiKey, 			dangerouslyAllowBrowser: true, // Enable browser-like environment usage 		}); 	}  	/** 	 * Check if the service is initialized 	 */ 	public isInitialized(): boolean { 		return this.client !== null; 	}  	/** 	 * Creates embeddings for the given text chunks with rate limiting and retries 	 */ 	async createEmbeddings(chunks: string[]): Promise<EmbeddingResponse[]> { 		if (!this.client) { 			console.warn('OpenAIService is not initialized. Cannot create embeddings.'); 			new Notice('OpenAI API key is missing. Please set it in the plugin settings.'); 			return chunks.map(() => ({ 				data: [], 				usage: { prompt_tokens: 0, total_tokens: 0 }, 				model: "text-embedding-ada-002", // Default model to maintain output consistency 			})); 		}  		const embeddings: EmbeddingResponse[] = []; 		for (let i = 0; i < chunks.length; i++) { 			try { 				const timeSinceLastRequest = Date.now() - this.lastRequestTime; 				if (timeSinceLastRequest < this.rateLimitDelay) { 					await new Promise(resolve => 						setTimeout(resolve, this.rateLimitDelay - timeSinceLastRequest) 					); 				}  				// Explicitly set the model to `text-embedding-ada-002` 				const response = await this.client.embeddings.create({ 					model: "text-embedding-ada-002", // Use the correct model 					input: chunks[i], 					encoding_format: "float", 				});  				this.lastRequestTime = Date.now();  				embeddings.push({ 					data: [ 						{ 							embedding: response.data[0].embedding, 							index: i, 						}, 					], 					usage: { 						prompt_tokens: response.usage.prompt_tokens, 						total_tokens: response.usage.total_tokens, 					}, 					model: response.model, 				}); 			} catch (error) { 				this.handleEmbeddingError(error, chunks[i]); 				embeddings.push({ 					data: [], 					usage: { prompt_tokens: 0, total_tokens: 0 }, 					model: "text-embedding-ada-002", 				}); 			} 		}  		return embeddings; 	}  	/** 	 * Handles various types of OpenAI API errors 	 */ 	private handleEmbeddingError(error: any, chunk: string): void { 		let errorMessage: string;  		if (error instanceof OpenAI.APIError) { 			switch (error.status) { 				case 429: 					errorMessage = 'Rate limit exceeded. Please try again later.'; 					break; 				case 401: 					errorMessage = 'Invalid API key. Please check your settings.'; 					break; 				case 413: 					errorMessage = 'Text chunk too large for embedding.'; 					break; 				default: 					errorMessage = `OpenAI API error: ${error.message}`; 			} 		} else { 			errorMessage = `Unexpected error: ${error.message}`; 		}  		// Log the error through the centralized error handler 		this.errorHandler.handleError(error, { 			context: 'OpenAIService.createEmbeddings', 			metadata: { 				chunkPreview: chunk.substring(0, 100) + '...' // First 100 chars for context 			} 		});  		new Notice(`Error creating embedding: ${errorMessage}`); 	}  	/** 	 * Updates service settings 	 */ 	updateSettings(settings: OpenAISettings): void { 		this.settings = settings;  		if (!settings.apiKey) { 			console.warn('OpenAI API key is missing. OpenAIService will not be initialized.'); 			this.client = null; 			return; 		}  		// Reinitialize the OpenAI client with updated settings 		this.client = new OpenAI({ 			apiKey: settings.apiKey, 			dangerouslyAllowBrowser: true, // Ensure this remains enabled 		}); 	}  	/** 	 * Updates rate limiting parameters 	 */ 	updateRateLimit(delayMs: number): void { 		this.rateLimitDelay = delayMs; 	} } 
### services/QueueService.ts ###
Filename: QueueService.ts

import { Vault, TFile } from 'obsidian'; import { TextSplitter } from '../utils/TextSplitter'; import {     ProcessingTask,     TaskStatus,     TaskType,     QueueStats,     TaskProgress,     TaskProcessingError, } from '../models/ProcessingTask'; import { ErrorHandler } from '../utils/ErrorHandler'; import { NotificationManager } from '../utils/NotificationManager'; import { SupabaseService } from './SupabaseService'; import { OpenAIService } from './OpenAIService'; import { DEFAULT_CHUNKING_OPTIONS } from '../settings/Settings';  export class QueueService {     private queue: ProcessingTask[] = [];     private processingQueue: ProcessingTask[] = [];     private isProcessing: boolean = false;     private isStopped: boolean = true;     private processingInterval: NodeJS.Timeout | null = null;     private textSplitter: TextSplitter;     private vault: Vault;      constructor(         private maxConcurrent: number,         private maxRetries: number,         private supabaseService: SupabaseService | null,         private openAIService: OpenAIService | null,         private errorHandler: ErrorHandler,         private notificationManager: NotificationManager,         vault: Vault,         chunkSettings?: { chunkSize: number; chunkOverlap: number; minChunkSize: number }     ) {         this.vault = vault;         const validatedChunkSettings = chunkSettings || { ...DEFAULT_CHUNKING_OPTIONS };          try {             this.textSplitter = new TextSplitter(validatedChunkSettings);         } catch (error) {             this.errorHandler.handleError(error, {                 context: 'QueueService.constructor',                 metadata: validatedChunkSettings,             });             throw new Error('Failed to initialize TextSplitter with provided settings.');         }     }      public start(): void {         if (!this.isStopped) return;          this.isStopped = false;         this.processQueue();          this.processingInterval = setInterval(() => {             if (!this.isProcessing) {                 this.processQueue();             }         }, 1000);     }      public stop(): void {         this.isStopped = true;         if (this.processingInterval) {             clearInterval(this.processingInterval);             this.processingInterval = null;         }     }      async addTask(task: ProcessingTask): Promise<void> {         if (this.queue.length >= 1000) {             throw new Error(TaskProcessingError.QUEUE_FULL);         }          console.log('Adding task to queue:', {             id: task.id,             type: task.type,             priority: task.priority         });          if (task.priority > 1) {             this.queue.unshift(task);         } else {             this.queue.push(task);         }          this.notifyProgress(task.id, 0, 'Task queued');          if (!this.isProcessing && !this.isStopped) {             this.processQueue();         }     }      private async processQueue(): Promise<void> {         if (this.isProcessing || this.isStopped || this.queue.length === 0) {             return;         }          this.isProcessing = true;          try {             while (this.queue.length > 0 && this.processingQueue.length < this.maxConcurrent) {                 const task = this.queue.shift();                 if (task) {                     this.processingQueue.push(task);                     this.processTask(task).catch((error) => {                         this.handleTaskError(task, error);                     });                 }             }         } catch (error) {             this.errorHandler.handleError(error, {                 context: 'QueueService.processQueue',             });         } finally {             this.isProcessing = false;         }     }      private async processTask(task: ProcessingTask): Promise<void> {         console.log('Processing task:', {             id: task.id,             type: task.type,             status: task.status         });          try {             task.status = TaskStatus.PROCESSING;             task.startedAt = Date.now();             this.notifyProgress(task.id, 0, `Starting ${task.type.toLowerCase()}`);              switch (task.type) {                 case TaskType.CREATE:                 case TaskType.UPDATE:                     await this.processCreateUpdateTask(task);                     break;                 case TaskType.DELETE:                     await this.processDeleteTask(task);                     break;                 default:                     throw new Error(`Unsupported task type: ${task.type}`);             }              task.status = TaskStatus.COMPLETED;             task.completedAt = Date.now();             this.notifyProgress(task.id, 100, 'Task completed');             console.log('Task completed successfully:', task.id);         } catch (error) {             console.error('Error processing task:', {                 taskId: task.id,                 error: error             });             await this.handleTaskError(task, error);         } finally {             this.removeFromProcessingQueue(task);         }     }      private async processCreateUpdateTask(task: ProcessingTask): Promise<void> {         if (!this.supabaseService || !this.openAIService) {             throw new Error('Required services not initialized');         }          try {             console.log('Reading file:', task.id);              // Get file from task path             const file = this.vault.getAbstractFileByPath(task.id);             if (!(file instanceof TFile)) {                 throw new Error(`File not found or not a TFile: ${task.id}`);             }              // Read file content             const content = await this.vault.read(file);             console.log('File content read successfully:', {                 fileId: task.id,                 contentLength: content.length,                 contentPreview: content.substring(0, 100)             });              // Split the content into chunks             this.notifyProgress(task.id, 20, 'Splitting content');             const chunks = this.textSplitter.splitDocument(content, task.metadata);             console.log('Content split into chunks:', {                 numberOfChunks: chunks.length,                 chunkSizes: chunks.map(c => c.content.length),                 firstChunkPreview: chunks[0]?.content.substring(0, 100)             });              if (chunks.length === 0) {                 console.warn('No chunks created for file:', {                     fileId: task.id,                     contentLength: content.length,                     settings: this.textSplitter.getSettings()                 });                 throw new Error('No chunks created from file content');             }              // Generate embeddings for each chunk             this.notifyProgress(task.id, 40, 'Generating embeddings');             for (let i = 0; i < chunks.length; i++) {                 const response = await this.openAIService.createEmbeddings([chunks[i].content]);                 if (response.length > 0 && response[0].data.length > 0) {                     chunks[i].embedding = response[0].data[0].embedding;                     console.log(`Generated embedding for chunk ${i + 1}/${chunks.length}`);                 } else {                     throw new Error(`Failed to generate embedding for chunk ${i + 1}`);                 }                  this.notifyProgress(                     task.id,                     40 + Math.floor((i / chunks.length) * 30),                     `Processed ${i + 1} of ${chunks.length} chunks`                 );             }              // Save chunks to database             this.notifyProgress(task.id, 70, 'Saving to database');             await this.supabaseService.upsertChunks(chunks);             console.log('Chunks saved to database:', {                 numberOfChunks: chunks.length,                 fileId: task.id             });              this.notifyProgress(task.id, 100, 'Processing completed');         } catch (error) {             console.error('Error in processCreateUpdateTask:', {                 error,                 taskId: task.id,                 metadata: task.metadata             });             throw error;         }     }      private async processDeleteTask(task: ProcessingTask): Promise<void> {         if (!this.supabaseService) {             throw new Error('Supabase service not initialized');         }          try {             this.notifyProgress(task.id, 50, 'Deleting from database');             await this.supabaseService.deleteDocumentChunks(task.metadata.obsidianId);             this.notifyProgress(task.id, 100, 'Delete completed');         } catch (error) {             console.error('Error in processDeleteTask:', {                 error,                 taskId: task.id,                 metadata: task.metadata             });             throw error;         }     }      private async handleTaskError(task: ProcessingTask, error: any): Promise<void> {         task.retryCount = (task.retryCount || 0) + 1;         task.updatedAt = Date.now();          if (task.retryCount < this.maxRetries) {             task.status = TaskStatus.RETRYING;             this.queue.unshift(task);              this.notifyProgress(task.id, 0, `Retry attempt ${task.retryCount}`);             console.log('Task queued for retry:', {                 taskId: task.id,                 retryCount: task.retryCount,                 maxRetries: this.maxRetries             });         } else {             task.status = TaskStatus.FAILED;             task.error = {                 message: error.message,                 code: error.code || 'UNKNOWN_ERROR',                 stack: error.stack,             };             task.completedAt = Date.now();             console.error('Task failed after max retries:', {                 taskId: task.id,                 error: task.error             });         }          this.errorHandler.handleError(error, {             context: 'QueueService.processTask',             taskId: task.id,             taskType: task.type,         });     }      private removeFromProcessingQueue(task: ProcessingTask): void {         const index = this.processingQueue.findIndex((t) => t.id === task.id);         if (index !== -1) {             this.processingQueue.splice(index, 1);         }     }      private notifyProgress(taskId: string, progress: number, message: string): void {         this.notificationManager.updateProgress({             taskId,             progress,             currentStep: message,             totalSteps: 1,             currentStepNumber: 1,         });     }      public getQueueStats(): QueueStats {         const now = Date.now();         const oneHour = 60 * 60 * 1000;          const tasksByStatus = this.queue.reduce((acc, task) => {             acc[task.status] = (acc[task.status] || 0) + 1;             return acc;         }, {} as Record<TaskStatus, number>);          const tasksByType = this.queue.reduce((acc, task) => {             acc[task.type] = (acc[task.type] || 0) + 1;             return acc;         }, {} as Record<TaskType, number>);          const completedTasks = this.queue.filter(             task => task.status === TaskStatus.COMPLETED && task.completedAt         );          const averageTime = completedTasks.length > 0             ? completedTasks.reduce((sum, task) => sum + (task.completedAt! - task.startedAt!), 0) / completedTasks.length             : 0;          const tasksLastHour = completedTasks.filter(             task => task.completedAt! > now - oneHour         ).length;          return {             totalTasks: this.queue.length,             tasksByStatus,             tasksByType,             averageProcessingTime: averageTime,             failedTasks: tasksByStatus[TaskStatus.FAILED] || 0,             retryingTasks: tasksByStatus[TaskStatus.RETRYING] || 0,             tasksLastHour,         };     }      public clear(): void {         this.queue = [];         this.processingQueue = [];         this.notificationManager.clear();     }      public updateSettings(settings: {         maxConcurrent: number;         maxRetries: number;         chunkSettings?: { chunkSize: number; chunkOverlap: number; minChunkSize: number };     }): void {         this.maxConcurrent = settings.maxConcurrent;         this.maxRetries = settings.maxRetries;          if (settings.chunkSettings) {             this.textSplitter = new TextSplitter(settings.chunkSettings);         }     } } 
### services/SupabaseService.ts ###
Filename: SupabaseService.ts

import { createClient, SupabaseClient } from '@supabase/supabase-js'; import { DocumentChunk, DocumentMetadata } from '../models/DocumentChunk'; import { MindMatrixSettings, isVaultInitialized } from '../settings/Settings'; import { Notice } from 'obsidian';  export class SupabaseService {     private client: SupabaseClient | null;     private static instance: SupabaseService | null = null;     private settings: MindMatrixSettings;     private readonly TABLE_NAME = 'obsidian_documents';      private constructor(settings: MindMatrixSettings) {         if (!settings.supabase.url || !settings.supabase.apiKey) {             console.warn('Supabase configuration is incomplete. Supabase service will not be initialized.');             this.client = null;             return;         }          if (!isVaultInitialized(settings)) {             throw new Error('Vault is not initialized');         }          this.settings = settings;         this.client = createClient(settings.supabase.url, settings.supabase.apiKey);     }      public static async getInstance(settings: MindMatrixSettings): Promise<SupabaseService | null> {         if (!settings.supabase.url || !settings.supabase.apiKey) {             console.warn('Supabase configuration is incomplete. Returning null.');             return null;         }          if (!SupabaseService.instance) {             SupabaseService.instance = new SupabaseService(settings);             await SupabaseService.instance.initializeDatabase();         } else if (             SupabaseService.instance.settings.supabase.url !== settings.supabase.url ||             SupabaseService.instance.settings.supabase.apiKey !== settings.supabase.apiKey ||             SupabaseService.instance.settings.vaultId !== settings.vaultId         ) {             SupabaseService.instance = new SupabaseService(settings);             await SupabaseService.instance.initializeDatabase();         }         return SupabaseService.instance;     }      private async initializeDatabase(): Promise<void> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping database initialization.');             return;         }          try {             new Notice('Checking database connection...');              // Verify we can access the database             const { data: testData, error: testError } = await this.client                 .from(this.TABLE_NAME)                 .select('id')                 .limit(1);              if (testError && !testError.message.includes('does not exist')) {                 throw new Error(`Database connection failed: ${testError.message}`);             }              // Initialize the database schema             const { error: initError } = await this.client                 .rpc('init_obsidian_documents');              if (initError) {                 throw new Error(`Failed to initialize database: ${initError.message}`);             }              new Notice('Database connection verified');             this.settings.supabase.initialized = true;          } catch (error) {             console.error('Database initialization error:', error);             new Notice(`Database error: ${error.message}`);             throw error;         }     }      public async upsertChunks(chunks: DocumentChunk[]): Promise<void> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping upsertChunks.');             return;         }          try {             if (chunks.length === 0) {                 console.log('No chunks to upsert');                 return;             }              // Get the obsidian_id from the first chunk             const obsidianId = chunks[0].metadata.obsidianId;              console.log('Attempting to delete existing chunks for:', obsidianId);              // First delete existing chunks for this file             const { error: deleteError } = await this.client                 .from(this.TABLE_NAME)                 .delete()                 .eq('vault_id', this.settings.vaultId)                 .eq('obsidian_id', obsidianId);              if (deleteError) {                 console.error('Error deleting existing chunks:', deleteError);                 throw deleteError;             }              // Prepare the new chunks for insertion             const chunksToInsert = chunks.map(chunk => ({                 vault_id: this.settings.vaultId,                 obsidian_id: chunk.metadata.obsidianId,                 chunk_index: chunk.chunkIndex,                 content: chunk.content,                 metadata: chunk.metadata,                 embedding: chunk.embedding,                 last_updated: new Date().toISOString()             }));              // Insert the new chunks             const { error: insertError } = await this.client                 .from(this.TABLE_NAME)                 .insert(chunksToInsert);              if (insertError) {                 console.error('Error inserting new chunks:', insertError);                 throw insertError;             }              console.log('Successfully updated chunks:', {                 numberOfChunks: chunks.length,                 vaultId: this.settings.vaultId,                 obsidianId             });         } catch (error) {             console.error('Failed to upsert chunks:', error);             throw error;         }     }      public async deleteDocumentChunks(obsidianId: string): Promise<void> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping deleteDocumentChunks.');             return;         }          try {             const { error } = await this.client                 .from(this.TABLE_NAME)                 .delete()                 .eq('vault_id', this.settings.vaultId)                 .eq('obsidian_id', obsidianId);              if (error) {                 throw error;             }         } catch (error) {             console.error('Failed to delete chunks:', error);             throw error;         }     }      public async getDocumentChunks(obsidianId: string): Promise<DocumentChunk[]> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping getDocumentChunks.');             return [];         }          try {             const { data, error } = await this.client                 .from(this.TABLE_NAME)                 .select('*')                 .eq('vault_id', this.settings.vaultId)                 .eq('obsidian_id', obsidianId)                 .order('chunk_index');              if (error) {                 throw error;             }              return data.map(row => ({                 content: row.content,                 chunkIndex: row.chunk_index,                 metadata: row.metadata as DocumentMetadata,                 embedding: row.embedding             }));         } catch (error) {             console.error('Failed to get chunks:', error);             throw error;         }     }      public async semanticSearch(embedding: number[], limit: number = 5): Promise<Array<{         content: string;         metadata: DocumentMetadata;         similarity: number;     }>> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping semanticSearch.');             return [];         }          try {             const { data, error } = await this.client.rpc('match_documents', {                 query_embedding: embedding,                 search_vault_id: this.settings.vaultId,                 match_count: limit             });              if (error) {                 throw error;             }              return data.map(row => ({                 content: row.content,                 metadata: row.metadata as DocumentMetadata,                 similarity: row.similarity             }));         } catch (error) {             console.error('Failed to perform semantic search:', error);             throw error;         }     }      public async testConnection(): Promise<boolean> {         if (!this.client) {             return false;         }          try {             const { error } = await this.client                 .from(this.TABLE_NAME)                 .select('id')                 .limit(1);              return !error;         } catch (error) {             return false;         }     }      public async getAllDocumentIds(): Promise<string[]> {         if (!this.client) {             console.warn('Supabase client is not initialized. Skipping getAllDocumentIds.');             return [];         }          try {             const { data, error } = await this.client                 .from(this.TABLE_NAME)                 .select('obsidian_id')                 .eq('vault_id', this.settings.vaultId)                 .distinct();              if (error) {                 throw error;             }              return data.map(row => row.obsidian_id);         } catch (error) {             console.error('Failed to get document IDs:', error);             throw error;         }     } } 